# Deployment and DevOps Guide

## 1. Introduction

**Project Title:** Interactive UFO/UAP Sightings Explorer & AI Analyst

This document provides a guide for deploying the Interactive UFO/UAP Sightings Explorer application. The application consists of a Python backend API (FastAPI) deployed on Google Cloud Run and a frontend UI (generated by Davia) deployed on Vercel.

This guide assumes familiarity with Git, Docker, Google Cloud Platform (GCP), and Vercel.

## 2. Prerequisites

*   **Google Cloud Platform (GCP) Account:** With billing enabled (though aiming for free tier usage).
    *   Google Cloud SDK (`gcloud` CLI) installed and configured.
    *   Permissions to create and manage Cloud Run services, Container Registry/Artifact Registry, and related resources.
*   **Vercel Account:** For deploying the frontend.
    *   Vercel CLI (optional, can deploy via Git integration).
*   **Docker Desktop:** Installed and running for building container images locally.
*   **Git:** For version control and integration with Vercel/GCP build processes.
*   **Project Code:** Cloned from the Git repository.
*   **Pre-processed Data:** The `nuforc_data.parquet` file must be generated and placed in the `backend/data/` directory (or as specified in the `Dockerfile`).

## 3. Backend Deployment (Python API on Google Cloud Run)

The backend is a containerized FastAPI application.

### 3.1. Backend Project Structure (Conceptual)

```
backend/
|-- app/
|   |-- main.py             # FastAPI application
|   |-- routers/            # Optional: API routers
|   |-- models/             # Optional: Pydantic models
|   |-- data/
|   |   |-- nuforc_data.parquet # Pre-processed data
|-- Dockerfile
|-- requirements.txt
|-- .gcloudignore           # To exclude unnecessary files from gcloud deployment
```

### 3.2. `Dockerfile` (Example)

```dockerfile
# Use an official Python runtime as a parent image
FROM python:3.9-slim

# Set the working directory in the container
WORKDIR /usr/src/app

# Install system dependencies if any (e.g., for certain Python packages)
# RUN apt-get update && apt-get install -y --no-install-recommends some-package && rm -rf /var/lib/apt/lists/*

# Copy the requirements file into the container
COPY requirements.txt ./

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy the rest of the application code into the container
COPY ./app /usr/src/app/app

# Expose the port the app runs on (FastAPI default is 8000 with Uvicorn)
EXPOSE 8000

# Command to run the application using Uvicorn
# The PORT environment variable is automatically set by Cloud Run.
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "$PORT"]
```
*(Note: Adjust `app.main:app` if your FastAPI app instance is named differently or located elsewhere. `$PORT` is crucial for Cloud Run.)*

### 3.3. `requirements.txt` (Example)

```
fastapi
uvicorn[standard] # Includes gunicorn as a worker option if needed, or just uvicorn
pandas
pyarrow         # For reading Parquet files
# Add other dependencies as needed
```

### 3.4. Building and Pushing the Docker Image

1.  **Enable APIs:** Ensure "Cloud Build API", "Artifact Registry API" (or "Container Registry API"), and "Cloud Run API" are enabled in your GCP project.
2.  **Authenticate Docker with GCP:**
    ```bash
    gcloud auth configure-docker YOUR_GCP_REGION-docker.pkg.dev
    ```
    (Replace `YOUR_GCP_REGION` with your region, e.g., `us-central1`)
3.  **Build the Docker Image:**
    Navigate to the `backend/` directory.
    ```bash
    docker build -t YOUR_GCP_REGION-docker.pkg.dev/YOUR_GCP_PROJECT_ID/YOUR_REPO_NAME/ufo-api:latest .
    ```
    (Replace placeholders with your GCP project ID, Artifact Registry repository name, etc.)
4.  **Push the Docker Image:**
    ```bash
    docker push YOUR_GCP_REGION-docker.pkg.dev/YOUR_GCP_PROJECT_ID/YOUR_REPO_NAME/ufo-api:latest
    ```

### 3.5. Deploying to Google Cloud Run

1.  **Deploy using `gcloud` CLI:**
    ```bash
    gcloud run deploy ufo-sightings-api \
        --image YOUR_GCP_REGION-docker.pkg.dev/YOUR_GCP_PROJECT_ID/YOUR_REPO_NAME/ufo-api:latest \
        --platform managed \
        --region YOUR_GCP_REGION \
        --allow-unauthenticated \
        --port 8000 \
        --memory 512Mi \
        --cpu 1
        # Add other flags as needed (e.g., --min-instances, --max-instances for free tier usually 0)
    ```
    *   `--allow-unauthenticated`: Makes the API publicly accessible (necessary for Vercel frontend to call it without complex auth for this demo).
    *   Adjust `--memory` and `--cpu` as needed, staying within free tier limits if possible. Pandas can be memory-intensive.
2.  **Note the Service URL:** After deployment, Cloud Run will provide a service URL (e.g., `https://ufo-sightings-api-xxxxxx-uc.a.run.app`). This URL is needed for the Davia platform/frontend.

## 4. Frontend Deployment (Davia UI on Vercel)

The frontend is generated by the Davia platform based on the OpenAPI specification from the deployed backend.

### 4.1. Davia Platform Configuration
1.  **Provide OpenAPI Spec:**
    *   The Davia platform requires the URL to your backend's `openapi.json` (usually exposed by FastAPI at `/openapi.json` relative to your service URL, e.g., `https://<your-gcr-service-url>/openapi.json`).
    *   Alternatively, you might upload the `openapi.json` file directly to Davia.
2.  **Configure Backend URL:** Ensure Davia knows the base URL of your deployed Google Cloud Run API service. This is how the Davia-generated frontend will make API calls.

### 4.2. Deployment to Vercel (General Steps - Davia might automate this)
*   **Option A: Davia Managed Deployment:** The Davia platform may have a direct integration or process for deploying the generated frontend to your Vercel account. Follow their specific instructions. This is the preferred method if available.
*   **Option B: Vercel Git Integration (If Davia outputs frontend code to your GitHub repository or you manage it there):**
    1.  **Connect GitHub Repository to Vercel:** In your Vercel dashboard, import the GitHub repository containing the frontend code (or the entire project if Davia structures it that way).
    2.  **Configure Project Settings:**
        *   Vercel typically auto-detects frontend frameworks (e.g., Next.js, React, Vue, or static sites). If Davia outputs standard static HTML/CSS/JS or a known framework structure, Vercel should handle it.
        *   Specify build commands and output directory if Vercel cannot auto-detect them (refer to Davia's documentation if it provides build steps).
        *   Set up Environment Variables: Crucially, the Vercel project must have an environment variable (e.g., `API_BASE_URL`, `NEXT_PUBLIC_API_URL`) pointing to your deployed Google Cloud Run backend service URL.
    3.  **Automatic Deployments:** Once connected, Vercel's CI/CD pipeline takes over:
        *   **Production Deployments:** Every push or merge to the main branch (e.g., `master` or `main`) will automatically trigger a build and deployment to your production Vercel URL.
        *   **Preview Deployments:** Every push to other branches or pull requests will automatically generate a unique preview deployment URL. This is excellent for testing changes before merging to main.

## 5. CI/CD (Continuous Integration/Continuous Deployment)

*   **Frontend (Vercel & GitHub):**
    *   **Automatic CI/CD:** As described in section 4.2 (Option B), Vercel's integration with GitHub provides a powerful, out-of-the-box CI/CD workflow.
        *   Commits to the main branch trigger production deployments.
        *   Commits to other branches or PRs trigger preview deployments.
    *   **No Manual Frontend Deployment Steps Needed:** After initial setup, frontend deployments are automated by Vercel based on Git activity.
*   **Backend (Google Cloud Run - Manual or Cloud Build):**
    *   **Manual Deployment (for this demo):** The steps outlined in section 3 (building and pushing Docker image, `gcloud run deploy`) are manual. This is sufficient for a demo project.
    *   **Automated CI/CD (Advanced/Optional):** For a production setup, Google Cloud Build could be configured with triggers on your GitHub repository (specifically for the `backend/` directory).
        *   A `cloudbuild.yaml` file would define steps to build the Docker image and deploy it to Cloud Run upon pushes to the backend code. This is considered out of scope for the initial setup of this demo project but is a standard practice for production CI/CD.

## 6. Post-Deployment Checks

1.  **Backend API:**
    *   Access the `/openapi.json` endpoint of your Cloud Run service to ensure it's serving the API spec.
    *   Manually test a few API endpoints using `curl` or Postman to verify they are working.
    *   Check Cloud Run logs for any startup errors.
2.  **Frontend Application:**
    *   Access the Vercel deployment URL.
    *   Perform manual functional testing as outlined in `06-Testing-Strategy-Document.md`.
    *   Use browser developer tools to check for console errors or failed API requests.

## 7. Rollback Strategy (Simplified)

*   **Google Cloud Run:** Cloud Run keeps previous revisions. You can quickly roll back to a previous working revision via the GCP Console or `gcloud` CLI.
*   **Vercel:** Vercel also maintains deployment history, allowing easy rollback to previous deployments.

This guide provides the fundamental steps for deploying the application. Specific commands and configurations might need adjustments based on the final project structure and the exact behavior of the Davia SDK and platform.
