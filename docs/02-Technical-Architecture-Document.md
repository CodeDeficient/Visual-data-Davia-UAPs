# Technical Architecture Document

## 1. Introduction

**Project Title:** Interactive UFO/UAP Sightings Explorer & AI Analyst

This document outlines the technical architecture for the Interactive UFO/UAP Sightings Explorer application. The system is designed with a decoupled frontend and backend, leveraging the Davia Python SDK for UI generation, Vercel for frontend hosting, and Google Cloud Run for the Python backend.

## 2. Architectural Goals

*   **Modularity:** Clearly separate frontend, backend (API), and data concerns.
*   **Scalability:** Utilize serverless platforms (Vercel, Google Cloud Run) that can scale with demand (though primarily targeting free-tier capabilities for this project).
*   **Maintainability:** Ensure components are well-defined and code is organized for ease of understanding and future modifications.
*   **Deployability:** Streamline the deployment process for both frontend and backend components.
*   **Rapid UI Development:** Leverage the Davia SDK to significantly accelerate frontend development by automatically generating the UI from the backend's OpenAPI specification, allowing focus on Python-based backend logic.
*   **Cost-Effectiveness:** Prioritize the use of free-tier services.
*   **Adherence to Davia Paradigm:** Follow the Davia model where the backend API (defined by an OpenAPI spec) drives the frontend UI.

## 3. System Overview

The application consists of three main layers:

1.  **Frontend (User Interface):**
    *   Generated by the Davia platform based on the OpenAPI specification provided by the backend.
    *   Hosted on Vercel.
    *   Responsible for rendering interactive components (maps, charts, filters, input fields) and communicating user interactions to the backend API.

2.  **Backend (API & Data Logic):**
    *   A Python application, likely built using FastAPI (as hinted in the job description and common for such use cases).
    *   Hosted on Google Cloud Run as a serverless container.
    *   Exposes API endpoints defined in an OpenAPI 3.0 specification.
    *   Handles data loading, processing (filtering, aggregation), and the logic for the AI analytical assistant.
    *   Interacts with the pre-processed UFO/UAP dataset.

3.  **Data Storage:**
    *   A pre-processed UFO/UAP sightings dataset (e.g., NUFORC from Kaggle).
    *   Stored in Parquet format for efficient loading by the Python backend.
    *   The Parquet file will be bundled with the backend application container deployed to Google Cloud Run. No external database service is planned to maintain cost-effectiveness.

## 4. Component Breakdown

### 4.1. Frontend (Vercel + Davia UI)

*   **Technology:** Davia UI (dynamically generated), HTML, CSS, JavaScript (managed by Davia).
*   **Hosting:** Vercel.
*   **Responsibilities:**
    *   Render the user interface based on components defined/implied by the Davia SDK's interpretation of the OpenAPI spec.
    *   Capture user inputs (filter changes, AI queries).
    *   Make API calls to the backend on Google Cloud Run to fetch data, apply filters, and get AI responses.
    *   Display data visualizations and results returned by the API.
*   **Key Interactions:**
    *   User interacts with UI elements (e.g., selects a filter).
    *   Frontend sends an API request to the backend.
    *   Frontend receives a response and updates the UI.

### 4.2. Backend (Python API on Google Cloud Run)

*   **Technology:** Python 3.x, FastAPI (recommended), Pandas (for data manipulation).
*   **Hosting:** Google Cloud Run (containerized).
*   **Responsibilities:**
    *   Implement API endpoints as defined in the OpenAPI specification.
    *   Load and manage the pre-processed Parquet dataset.
    *   Perform data filtering, aggregation, and calculations based on API requests.
    *   Implement the logic for the rule-based AI analytical assistant.
    *   Return data (JSON format) to the frontend.
*   **Structure (Conceptual - using FastAPI):**
    *   `main.py` (or similar): Initializes the FastAPI application, loads data, defines API routes.
    *   `routers/` (optional): Separate modules for different groups of API endpoints (e.g., `data_exploration.py`, `ai_assistant.py`).
    *   `data/`: Directory containing the `nuforc_data.parquet` file.
    *   `models/` (optional): Pydantic models for request/response validation if using FastAPI.
    *   `Dockerfile`: To containerize the Python application for Google Cloud Run.
    *   `requirements.txt`: Lists Python dependencies.
*   **Key Interactions:**
    *   Receives API requests from the Vercel-hosted frontend.
    *   Processes requests: reads data from the Parquet file, applies logic.
    *   Sends JSON responses back to the frontend.

### 4.3. Data Layer

*   **Source:** NUFORC UFO Sightings dataset (from Kaggle).
*   **Preprocessing (Offline Task):**
    *   Clean the raw CSV data.
    *   Filter out unnecessary columns or rows with missing critical data.
    *   Convert to Parquet format (`nuforc_data.parquet`).
    *   This pre-processed file is then included in the backend's deployment package.
*   **Runtime Access:** The Python backend on Google Cloud Run reads this local Parquet file directly into a Pandas DataFrame upon startup or on demand.

## 5. Data Flow Diagram

```mermaid
graph TD
    User[End User] -- Interacts --> Frontend_Vercel[Frontend on Vercel (Davia UI)]
    Frontend_Vercel -- API Requests (HTTPS) --> Backend_GCR[Python Backend on Google Cloud Run (FastAPI)]
    Backend_GCR -- Loads/Reads --> ParquetFile[nuforc_data.parquet (Bundled)]
    Backend_GCR -- Processes Data (Pandas) --> Backend_GCR
    Backend_GCR -- API Responses (JSON) --> Frontend_Vercel
    Frontend_Vercel -- Renders UI Updates --> User

    subgraph Davia Ecosystem
        DaviaPlatform[Davia Platform] -- Generates UI based on --> OpenAPISpec[OpenAPI Specification]
        Backend_GCR -- Provides --> OpenAPISpec
    end
```

## 6. Deployment Architecture

*   **Frontend Deployment:**
    *   The Davia platform likely handles the generation of the frontend assets.
    *   These assets are deployed to Vercel.
    *   Vercel configuration (`vercel.json` if needed, or through Davia's deployment process) will point API calls to the Google Cloud Run backend URL.
*   **Backend Deployment:**
    *   The Python/FastAPI application is containerized using a `Dockerfile`.
    *   The Docker image (including the Python app and the `nuforc_data.parquet` file) is pushed to Google Container Registry (GCR) or Artifact Registry.
    *   A Google Cloud Run service is created, configured to run this container image.
    *   The Cloud Run service will have a public HTTPS endpoint, which the frontend will call.
    *   Environment variables on Cloud Run can be used for any necessary configuration.

## 7. API Design (High-Level)

*   The API will be RESTful and defined using OpenAPI 3.0.
*   Endpoints will cover:
    *   Fetching initial dataset overview/summary.
    *   Applying filters and retrieving filtered data/visualizations.
    *   Submitting queries to the AI assistant and getting responses.
*   Detailed API design will be in `04-API-Documentation-Standards.md`. Davia's documentation states it uses the OpenAPI JSON specification as input.

## 8. Key Technical Decisions & Justifications

*   **Python with FastAPI for Backend:** FastAPI is modern, fast, supports asynchronous operations (good for I/O bound tasks like data reading), and has excellent OpenAPI support, which is critical for Davia.
*   **Pandas for Data Manipulation:** Standard and efficient library for data operations in Python.
*   **Parquet for Data Storage:** Offers better compression and read performance compared to CSV for Pandas DataFrames, suitable for a serverless environment where startup time can be a factor.
*   **Vercel for Frontend:** As specified by Davia's deployment architecture. Excellent for hosting static/frontend applications with good performance and CI/CD integration.
*   **Google Cloud Run for Backend:** As specified by Davia's deployment architecture. Scalable, serverless, cost-effective (pay-per-use, generous free tier), and well-suited for containerized Python applications.
*   **Rule-Based AI Assistant (Initial):** To ensure cost-effectiveness and simplicity, a rule-based approach for the AI assistant is prioritized. This avoids reliance on paid LLM APIs.

This architecture provides a robust, scalable, and maintainable foundation for the Interactive UFO/UAP Sightings Explorer, aligning with Davia's recommended deployment strategy and the project's goals.
